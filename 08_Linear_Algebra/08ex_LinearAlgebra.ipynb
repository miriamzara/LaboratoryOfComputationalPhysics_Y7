{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 08 Exercises: Linear Algebra (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\\. PCA on 3D dataset\n",
    "\n",
    "1. Generate a dataset with $M = 3$ features and N ${\\cal O}(1000)$ measurements. Specifically, with $N(\\mu,\\sigma)$ the normal distribution with mean $\\mu$ and $\\sigma$  standard deviation, generate the 3 features $x_{1,2,3}$ such that:\n",
    "    * $x_1$ is distributed as $N(0,1)$\n",
    "    * $x_2$ is distributed as $x_1+N(0,3)$\n",
    "    * $x_3$ is given by $2x_1+x_2$\n",
    "2. Find the eigenvectors and eigenvalues of the covariance matrix of the dataset.\n",
    "3. Find the eigenvectors and eigenvalues using SVD. Check that the two procedures yield to same result, being the covariance matrix symmetric.\n",
    "4. What percent of the total dataset's variability is explained by the principal components? Given how the dataset was constructed, do these make sense? Reduce the dimensionality of the system so that at least 99% of the total variability is retained.\n",
    "5. Redefine the data in the basis yielded by the PCA procedure.\n",
    "6. Plot the data points in the original and the new coordinates as a set of scatter plots. Your final figure should have 2 rows of 3 plots each, where the columns show the (0,1), (0,2) and (1,2) proejctions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\n",
    "\n",
    "Generate a dataset with $M = 3$ features and N ${\\cal O}(1000)$ measurements. Specifically, with $N(\\mu,\\sigma)$ the normal distribution with mean $\\mu$ and $\\sigma$  standard deviation, generate the 3 features $x_{1,2,3}$ such that:\n",
    "    * $x_1$ is distributed as $N(0,1)$\n",
    "    * $x_2$ is distributed as $x_1+N(0,3)$\n",
    "    * $x_3$ is given by $2x_1+x_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.626709</td>\n",
       "      <td>0.104184</td>\n",
       "      <td>1.357602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.984555</td>\n",
       "      <td>-7.457642</td>\n",
       "      <td>-5.488532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.435850</td>\n",
       "      <td>-2.371178</td>\n",
       "      <td>-3.242878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.347136</td>\n",
       "      <td>5.250045</td>\n",
       "      <td>4.555774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.192992</td>\n",
       "      <td>4.451389</td>\n",
       "      <td>8.837374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.599057</td>\n",
       "      <td>-1.216198</td>\n",
       "      <td>-0.018083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.974952</td>\n",
       "      <td>-2.296643</td>\n",
       "      <td>-6.246547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.217803</td>\n",
       "      <td>-0.170506</td>\n",
       "      <td>0.265100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.229704</td>\n",
       "      <td>0.964773</td>\n",
       "      <td>1.424180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.497885</td>\n",
       "      <td>2.434779</td>\n",
       "      <td>5.430549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3\n",
       "0    0.626709  0.104184  1.357602\n",
       "1    0.984555 -7.457642 -5.488532\n",
       "2   -0.435850 -2.371178 -3.242878\n",
       "3   -0.347136  5.250045  4.555774\n",
       "4    2.192992  4.451389  8.837374\n",
       "..        ...       ...       ...\n",
       "995  0.599057 -1.216198 -0.018083\n",
       "996 -1.974952 -2.296643 -6.246547\n",
       "997  0.217803 -0.170506  0.265100\n",
       "998  0.229704  0.964773  1.424180\n",
       "999  1.497885  2.434779  5.430549\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import random\n",
    "import numpy as np\n",
    "random.seed(102340)\n",
    "\n",
    "N = 1000\n",
    "x1 = random.normal(loc= 0, scale = 1, size = N)\n",
    "x2 = x1 + random.normal(loc= 0, scale = 3, size = N)\n",
    "x3 = 2*x1 + x2\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'x1': x1,\n",
    "        'x2': x2,\n",
    "        'x3': x3\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "\n",
    "Find the eigenvectors and eigenvalues of the covariance matrix of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1000)\n",
      "eigenvectors: \n",
      " [[-0.11185642 -0.81649658  0.56641105]\n",
      " [-0.5818526  -0.40824829 -0.70340663]\n",
      " [-0.80556545  0.40824829  0.42941547]]\n",
      "\n",
      "eigenvalues: \n",
      " [2.61765766e+01+0.j 2.17820035e-16+0.j 2.07652988e+00+0.j]\n",
      "\n",
      "eigenvalues (real): \n",
      " [2.61765766e+01 2.17820035e-16 2.07652988e+00]\n"
     ]
    }
   ],
   "source": [
    "# Covariance\n",
    "\n",
    "# To feed the np.cov built in function, the data shall be passed as an array with nrows= features, ncols= N\n",
    "data_array = np.vstack((x1, x2, x3))\n",
    "print(data_array.shape)\n",
    "covariance_matrix = np.cov(data_array)\n",
    "\n",
    "covariance_matrix\n",
    "\n",
    "# Eigenvalues, eigenvectors using diagonalization\n",
    "from scipy import linalg as la\n",
    "eigval, eigvect = la.eig(covariance_matrix)\n",
    "\n",
    "print (\"eigenvectors: \\n\", eigvect, end = '\\n\\n')\n",
    "print (\"eigenvalues: \\n\", eigval, end = '\\n\\n') # by default, this returns complex values. but in this case (cov is symmetric)...\n",
    "print(\"eigenvalues (real): \\n\", np.real_if_close(eigval)) # ... we now the eigval are real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. \n",
    "\n",
    "Find the eigenvectors and eigenvalues using SVD. Check that the two procedures yield to same result, being the covariance matrix symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.61765766e+01 2.07652988e+00 1.06804701e-15] \n",
      "\n",
      "\n",
      "[[-0.11185642  0.56641105 -0.81649658]\n",
      " [-0.5818526  -0.70340663 -0.40824829]\n",
      " [-0.80556545  0.42941547  0.40824829]] \n",
      "\n",
      "\n",
      "[[-0.11185642  0.56641105 -0.81649658]\n",
      " [-0.5818526  -0.70340663 -0.40824829]\n",
      " [-0.80556545  0.42941547  0.40824829]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eigenvalues, eigenvectors using SVD\n",
    "# For a square matrix, these must be the same\n",
    "\n",
    "U, spectrum, Vt = la.svd(covariance_matrix)\n",
    "\n",
    "print (spectrum,'\\n\\n')\n",
    "print (U,'\\n\\n')\n",
    "#print (Vt,'\\n\\n')\n",
    "print( Vt.T, '\\n\\n') # U and V are the same, as expected for a square matrix\n",
    "# the eigenvalue order has changed because the vector space basis has changed too (see component 2 and 3 of each eigvect is inverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we would have expected, there is an almost zero eigenvalue: this corresponds to the fact that x3 is a linear combination of x1 and x2 with no statistical noise at all.\n",
    "\n",
    "The two other eigenvalues have magnitude ratio 1:10. It corresponds to the fact that the std of the two variables x1 and x2 is different.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \n",
    "\n",
    "What percent of the total dataset's variability is explained by the principal components? Given how the dataset was constructed, do these make sense? Reduce the dimensionality of the system so that at least 99% of the total variability is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.61765766e+01, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 2.17820035e-16, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.07652988e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigval = np.real_if_close(eigval)\n",
    "Lambda_ = np.diag(eigval)\n",
    "Lambda_\n",
    "\n",
    "p = 1 # principal components retained\n",
    "e\n",
    "explained_variability = np.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'zero'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Rotate the data according to the new basis\u001b[39;00m\n\u001b[1;32m      3\u001b[0m covariance_matrix_rotated \u001b[38;5;241m=\u001b[39m eigvect\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m covariance_matrix \u001b[38;5;241m@\u001b[39m eigvect\n\u001b[0;32m----> 5\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero\u001b[49m\n",
      "File \u001b[0;32m~/LaboratoryOfComputationalPhysics_Y7/myenv/lib/python3.12/site-packages/numpy/__init__.py:410\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'zero'"
     ]
    }
   ],
   "source": [
    "# Rotate the data according to the new basis\n",
    "\n",
    "covariance_matrix_rotated = eigvect.T @ covariance_matrix @ eigvect\n",
    "\n",
    "np.zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\\. PCA on a nD dataset\n",
    "\n",
    "Start from the dataset you have genereted in the previous exercise and add uncorrelated random noise. Such noise should be represented by other 10 uncorrelated variables normal distributed, with standar deviation much smaller (say, a factor 50) than those used to generate the $x_1$ and $x_2$.\n",
    "\n",
    "Repeat the PCA procedure and compare the results with what you obtained before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 \\. Looking at an oscillating spring (optional)\n",
    "\n",
    "Imagine you have $n$ cameras looking at a spring oscillating along the $x$ axis. Each  camera record the motion of the spring looking at it along a given direction defined by the pair $(\\theta_i, \\phi_i)$, the angles in spherical coordinates. \n",
    "\n",
    "Start from the simulation of the records (say ${\\cal O}(1000)$) of the spring's motion along the x axis, assuming a little random noise affects the measurements along the $y$. Rotate such dataset to emulate the records of each camera.\n",
    "\n",
    "Perform a Principal Component Analysis on the thus obtained dataset, aiming at finding the only one coordinate that really matters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\\. PCA on the MAGIC dataset (optional)\n",
    "\n",
    "Perform a PCA on the magic04.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset and its description on the proper data directory\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data -P ~/data/\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.names -P ~/data/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
